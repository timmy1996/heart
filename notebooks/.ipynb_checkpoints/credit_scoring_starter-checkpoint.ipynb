{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0219298a",
   "metadata": {},
   "source": [
    "\n",
    "# Credit Scoring Project — Starter Notebook (Banking Style)\n",
    "\n",
    "**Objective:** Build a **logistic regression credit scorecard-style model** to predict **default** (PD).  \n",
    "**Datasets:** Prefer the *UCI Credit Card Default* (Taiwan) or *German Credit* (UCI).  \n",
    "**Deliverables:** Clean EDA, compliant preprocessing, baseline logistic model, metrics (AUC/KS/Gini), drift (PSI), and an executive summary.\n",
    "\n",
    "> Tip: Keep an **audit trail** — record data sources, transformations, versions, and model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a172ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 0) Setup -----------------------------------------------------------------\n",
    "# If running locally, consider creating a new virtual environment.\n",
    "# Optional installs (uncomment if you have internet & permissions):\n",
    "# %pip install pandas numpy scikit-learn matplotlib seaborn shap optbinning scorecardpy\n",
    "\n",
    "import os, sys, math, textwrap, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "# Try optional libraries (if installed)\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    shap = None\n",
    "\n",
    "try:\n",
    "    import optbinning as _optbinning\n",
    "except Exception:\n",
    "    _optbinning = None\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0fee8",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data Loading\n",
    "\n",
    "You can use either:\n",
    "- **UCI Credit Card Default** (recommended): https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients  \n",
    "- **German Credit**: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
    "\n",
    "The code below tries to load from a local `data/credit_default.csv`.  \n",
    "If not found, it will **attempt** to download the UCI default dataset CSV mirror (requires internet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1) Data loading -----------------------------------------------------------\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "local_path = DATA_DIR / \"credit_default.csv\"\n",
    "\n",
    "if local_path.exists():\n",
    "    df = pd.read_csv(local_path)\n",
    "else:\n",
    "    # Attempt a direct download of a preprocessed CSV from a common mirror (schema-compatible)\n",
    "    # If this fails (no internet), manually place your CSV at data/credit_default.csv\n",
    "    try:\n",
    "        url = \"https://raw.githubusercontent.com/plotly/datasets/master/credit-card-default.csv\"\n",
    "        df = pd.read_csv(url)\n",
    "        df.to_csv(local_path, index=False)\n",
    "        print(f\"Downloaded dataset to {local_path}\")\n",
    "    except Exception as e:\n",
    "        raise SystemExit(f\"Could not load data. Place your dataset at {local_path}. Error: {e}\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351b9aa",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Exploratory Data Analysis (EDA)\n",
    "\n",
    "Bank-style checks:\n",
    "- Target distribution (class imbalance).\n",
    "- Missing values & data types.\n",
    "- Basic univariate distributions.\n",
    "- Leakage checks (post-outcome features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fcebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2) EDA -------------------------------------------------------------------\n",
    "target_col_candidates = [c for c in df.columns if c.lower() in (\"default\", \"default.payment.next.month\", \"y\", \"target\")]\n",
    "if not target_col_candidates:\n",
    "    # Heuristic for the UCI Taiwan dataset mirror\n",
    "    # The Plotly mirror uses 'default payment next month' or 'default' depending on version\n",
    "    for cand in df.columns:\n",
    "        if \"default\" in cand.lower():\n",
    "            target_col_candidates.append(cand)\n",
    "target_col = target_col_candidates[0]\n",
    "\n",
    "print(\"Target column:\", target_col)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values (top 20):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# Target distribution\n",
    "vc = df[target_col].value_counts(dropna=False).sort_index()\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(vc, \"\\nShare:\", (vc / len(df)).round(3))\n",
    "\n",
    "# Simple histogram for a few numeric predictors\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "sample_numeric = numeric_cols[:6]\n",
    "\n",
    "for col in sample_numeric:\n",
    "    df[col].hist(bins=40)\n",
    "    plt.title(f\"Histogram: {col}\")\n",
    "    plt.xlabel(col); plt.ylabel(\"Count\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2f11f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Train/Test Split\n",
    "\n",
    "We hold out a test set for **unseen evaluation**. Optionally also create a validation set for tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3) Split -----------------------------------------------------------------\n",
    "y = df[target_col].astype(int)\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fd6f0",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Preprocessing\n",
    "\n",
    "**Two tracks** (choose based on your environment):\n",
    "\n",
    "- **(A) Scorecard-style** (preferred for regulated risk): supervised binning (WOE/IV) via `optbinning` then logistic regression with monotonicity if applicable.\n",
    "- **(B) Simpler baseline**: one-hot encode categoricals + standardize numerics, logistic regression.\n",
    "\n",
    "Below we implement **(B) baseline** (always available). If `optbinning` is installed, a WOE/IV path is sketched.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a882ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4A) Baseline preprocessing (OHE + scaling) -------------------------------\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"logreg\", LogisticRegression(max_iter=200, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "\n",
    "y_prob_test = baseline_clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(f\"Baseline Logistic AUC: {auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d922ebe",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Risk Metrics: ROC, KS, Gini, Confusion Matrix\n",
    "\n",
    "- **AUC (ROC)** — overall ranking quality.  \n",
    "- **KS** — max separation between positive/negative CDFs (common in credit risk).  \n",
    "- **Gini** — `2*AUC - 1`.  \n",
    "- **Threshold selection** — show confusion matrix at a business-relevant cutoff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5) Metrics & plots -------------------------------------------------------\n",
    "def ks_statistic(y_true, y_score):\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_score)\n",
    "    ks = max(tpr - fpr)\n",
    "    return ks\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_test, y_prob_test)\n",
    "ks = ks_statistic(y_test, y_prob_test)\n",
    "gini = 2 * roc_auc_score(y_test, y_prob_test) - 1\n",
    "\n",
    "print(f\"AUC:  {roc_auc_score(y_test, y_prob_test):.3f}\")\n",
    "print(f\"KS:   {ks:.3f}\")\n",
    "print(f\"Gini: {gini:.3f}\")\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc_score(y_test, y_prob_test):.3f})\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Example threshold selection (You can tune this based on business costs)\n",
    "cut = np.quantile(y_prob_test, 0.8)  # top 20% as 'risky' example\n",
    "y_pred_test = (y_prob_test >= cut).astype(int)\n",
    "print(\"\\nConfusion Matrix @ 80th percentile cutoff:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_test, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116242f",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Population Stability Index (PSI)\n",
    "\n",
    "Compares score distributions between two samples (e.g., **train vs test** or **time A vs time B**). Large PSI may indicate **drift**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6) PSI -------------------------------------------------------------------\n",
    "def psi(expected, actual, buckets=10, range_margin=0.001):\n",
    "    expected = np.array(expected); actual = np.array(actual)\n",
    "    # define buckets by expected quantiles\n",
    "    quantiles = np.linspace(0 + range_margin, 1 - range_margin, buckets - 1)\n",
    "    cuts = np.quantile(expected, quantiles)\n",
    "    expected_bins = np.digitize(expected, cuts)\n",
    "    actual_bins = np.digitize(actual, cuts)\n",
    "\n",
    "    def dist(bins, size):\n",
    "        counts = np.bincount(bins, minlength=buckets)\n",
    "        perc = counts / size\n",
    "        return perc + 1e-10  # smooth to avoid div-by-zero\n",
    "\n",
    "    e_perc = dist(expected_bins, expected.shape[0])\n",
    "    a_perc = dist(actual_bins, actual.shape[0])\n",
    "\n",
    "    return np.sum((a_perc - e_perc) * np.log(a_perc / e_perc))\n",
    "\n",
    "# Compute model score (prob) for train as well\n",
    "y_prob_train = baseline_clf.predict_proba(X_train)[:, 1]\n",
    "psi_train_test = psi(y_prob_train, y_prob_test, buckets=10)\n",
    "print(f\"PSI (Train vs Test): {psi_train_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0e09c",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (Optional) WOE/IV Binning Path with `optbinning`\n",
    "\n",
    "If `optbinning` is installed, you can compute **IV** (variable strength) and produce **WOE-transformed** features for a classic **scorecard** workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 7) WOE/IV (optional) -----------------------------------------------------\n",
    "if _optbinning is None:\n",
    "    print(\"optbinning not installed; skipping WOE/IV demo.\")\n",
    "else:\n",
    "    from optbinning import OptimalBinning\n",
    "    iv_table = []\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            ob = OptimalBinning(name=col, dtype=\"numerical\", solver=\"mip\", monotonic_trend=None)\n",
    "            ob.fit(X_train[col].values, y_train.values)\n",
    "            iv = ob.information_value_\n",
    "            iv_table.append((col, iv))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    iv_df = pd.DataFrame(iv_table, columns=[\"feature\", \"IV\"]).sort_values(\"IV\", ascending=False)\n",
    "    display(iv_df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55315174",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Explainability (SHAP)\n",
    "\n",
    "Use **SHAP** values to explain individual predictions and global feature importance (if `shap` is installed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 8) SHAP (optional) -------------------------------------------------------\n",
    "if shap is None:\n",
    "    print(\"SHAP not installed; skipping explainability plots.\")\n",
    "else:\n",
    "    # Use a sample for speed\n",
    "    X_test_sample = X_test.sample(min(200, len(X_test)), random_state=RANDOM_STATE)\n",
    "    # Use predict_proba on the pipeline via a KernelExplainer (model-agnostic)\n",
    "    def f_model(X_array):\n",
    "        return baseline_clf.predict_proba(pd.DataFrame(X_array, columns=X_test.columns))[:, 1]\n",
    "\n",
    "    explainer = shap.KernelExplainer(f_model, X_test_sample, link=\"logit\")\n",
    "    shap_values = explainer.shap_values(X_test_sample, nsamples=100)\n",
    "    shap.summary_plot(shap_values, X_test_sample, show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c762809",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Model Report (Executive/Risk Style) — Outline\n",
    "\n",
    "**Business Objective:** Predict probability of default (PD) for credit applicants to improve underwriting & portfolio risk management.  \n",
    "**Data:** Source, period, key fields, exclusions.  \n",
    "**Method:** Train/test split, preprocessing steps, logistic regression specs, hyperparameters.  \n",
    "**Performance:** AUC, KS, Gini, confusion, calibration plots.  \n",
    "**Stability:** PSI, drift checks, backtesting (if time-split available).  \n",
    "**Governance:** Assumptions, limitations, fairness checks, documentation of versions.  \n",
    "**Decisioning:** Example cutoffs, expected approvals/declines, loss impacts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861edbab",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Next Steps\n",
    "\n",
    "- Add **calibration** (Platt scaling or isotonic).  \n",
    "- Add **reject inference** (if you have accepted-only bias).  \n",
    "- Try **monotonic constraints** (e.g., XGBoost) for regulator-friendly behavior.  \n",
    "- Productionize: **MLflow** tracking, **Airflow** pipeline, **Docker** packaging.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
