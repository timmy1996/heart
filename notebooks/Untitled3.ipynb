{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60cef45a-f8d4-4c23-89c3-166cf4d81b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d7ab80-c743-4ee7-8cb8-0917e9c4884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import classification_report, fbeta_score, precision_score, recall_score, accuracy_score\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "def numeric_selector_after_poly(df):\n",
    "    return [c for c in df.columns if c not in categorical_vars]\n",
    "X_test =  pd.read_csv(\"../data/testing_features.csv\").drop(columns=[\"RestingBP\",\"RestingECG\"])\n",
    "y_test = pd.read_csv(\"../data/testing_labels.csv\")\n",
    "ARTI_DIR = \"artifacts/final_oldpeak_yj_poly_tuned\"   \n",
    "pipeline = load(f\"{ARTI_DIR}/pipeline.joblib\")\n",
    "with open(f\"{ARTI_DIR}/threshold.json\") as f:\n",
    "    threshold = float(json.load(f)[\"best_threshold\"])\n",
    "\n",
    "\n",
    "saved_cols = pd.read_csv(f\"{ARTI_DIR}/columns.csv\")[\"columns\"].tolist()\n",
    "assert list(X_test.columns) == saved_cols, \"Column order/names mismatch with training artifacts.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b073057d-cf41-4de0-809d-33f291fa2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold used: 0.22479016604179114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Threshold used:\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec6d5ec-ad69-4bee-903b-56ffdf0eb320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (pos class): 0.9803921568627451\n",
      "Precision (pos class): 0.7299270072992701\n",
      "Accuracy: 0.7880434782608695\n",
      "F2: 0.9174311926605505\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.55      0.70        82\n",
      "           1       0.73      0.98      0.84       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.84      0.76      0.77       184\n",
      "weighted avg       0.83      0.79      0.77       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (p_test >= threshold).astype(int)\n",
    "print(\"Recall (pos class):\", recall_score(y_test, y_test_pred, zero_division=0))\n",
    "print(\"Precision (pos class):\", precision_score(y_test, y_test_pred, zero_division=0))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"F2:\", fbeta_score(y_test, y_test_pred, beta=2, zero_division=0))\n",
    "print(\"\\nClassification report (test):\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033be1f2-d6d3-4848-88df-0089890736a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Test Metrics ===\n",
      "|   threshold |   recall_pos |   precision_pos |   accuracy |     F2 |   roc_auc |   pr_auc |   specificity |   TP |   FP |   TN |   FN |\n",
      "|------------:|-------------:|----------------:|-----------:|-------:|----------:|---------:|--------------:|-----:|-----:|-----:|-----:|\n",
      "|       0.225 |       0.9804 |          0.7299 |      0.788 | 0.9174 |    0.9275 |   0.9377 |        0.5488 |  100 |   37 |   45 |    2 |\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.55      0.70        82\n",
      "           1       0.73      0.98      0.84       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.84      0.76      0.77       184\n",
      "weighted avg       0.83      0.79      0.77       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    precision_score, recall_score, accuracy_score, fbeta_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve\n",
    ")\n",
    "\n",
    "# --- Ensure assets dir exists\n",
    "os.makedirs(\"assets\", exist_ok=True)\n",
    "\n",
    "# --- Base predictions (you already have these)\n",
    "# p_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "# y_test_pred = (p_test >= threshold).astype(int)\n",
    "\n",
    "# --- Core metrics\n",
    "rec = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "prec = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f2  = fbeta_score(y_test, y_test_pred, beta=2, zero_division=0)\n",
    "\n",
    "# Threshold-free metrics\n",
    "roc_auc = roc_auc_score(y_test, p_test)\n",
    "pr_auc  = average_precision_score(y_test, p_test)\n",
    "\n",
    "# Confusion matrix + specificity\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=[0,1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "# --- Metrics table (nice for README)\n",
    "metrics_df = pd.DataFrame([{\n",
    "    \"threshold\": round(float(threshold), 3),\n",
    "    \"recall_pos\": rec,\n",
    "    \"precision_pos\": prec,\n",
    "    \"accuracy\": acc,\n",
    "    \"F2\": f2,\n",
    "    \"roc_auc\": roc_auc,\n",
    "    \"pr_auc\": pr_auc,\n",
    "    \"specificity\": specificity,\n",
    "    \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn,\n",
    "}]).round(4)\n",
    "\n",
    "print(\"=== Final Test Metrics ===\")\n",
    "print(metrics_df.to_markdown(index=False))\n",
    "print(\"\\nClassification report (test):\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "# ===========================\n",
    "# Figures\n",
    "# ===========================\n",
    "\n",
    "# --- 1) Confusion matrix (counts)\n",
    "fig, ax = plt.subplots(figsize=(4.8, 4.2))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_title(f\"Confusion Matrix (Test @ threshold={threshold:.3f})\")\n",
    "ax.set_xticks([0,1]); ax.set_xticklabels([\"0\",\"1\"])\n",
    "ax.set_yticks([0,1]); ax.set_yticklabels([\"0\",\"1\"])\n",
    "\n",
    "# annotate counts\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, f\"{val}\", ha=\"center\", va=\"center\",\n",
    "            fontsize=11, color=(\"white\" if cm.max()/2 < val else \"black\"))\n",
    "\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"assets/fig_confusion_test.png\", dpi=220)\n",
    "plt.close(fig)\n",
    "\n",
    "# --- 2) PR curve (mark operating point)\n",
    "prec_curve, rec_curve, pr_thresh = precision_recall_curve(y_test, p_test)\n",
    "op_prec = prec\n",
    "op_rec  = rec\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4.2))\n",
    "ax.plot(rec_curve, prec_curve, label=f\"PR curve (AP={pr_auc:.3f})\")\n",
    "ax.scatter([op_rec], [op_prec], s=50, marker=\"o\", label=f\"Operating point @ {threshold:.3f}\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(\"Precisionâ€“Recall (Test)\")\n",
    "ax.legend(loc=\"lower left\")\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"assets/fig_prcurve_test.png\", dpi=220)\n",
    "plt.close(fig)\n",
    "\n",
    "# --- 3) ROC curve (mark operating point)\n",
    "fpr, tpr, roc_thresh = roc_curve(y_test, p_test)\n",
    "op_fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "op_tpr = rec\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4.2))\n",
    "ax.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.3f})\")\n",
    "ax.plot([0,1], [0,1], linestyle=\"--\", linewidth=1)  # chance line\n",
    "ax.scatter([op_fpr], [op_tpr], s=50, marker=\"o\", label=f\"Operating point @ {threshold:.3f}\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate (Recall)\")\n",
    "ax.set_title(\"ROC (Test)\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"assets/fig_roc_test.png\", dpi=220)\n",
    "plt.close(fig)\n",
    "\n",
    "# --- Optional: save a CSV/JSON with metrics for reproducibility\n",
    "metrics_df.to_csv(\"assets/test_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b272e-842f-413a-9ea5-641aaa02889f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
